{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b251a4d7-7b73-44cb-aec5-3770d290467f",
   "metadata": {},
   "source": [
    "# Sample DiviK run\n",
    "\n",
    "## Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f24dff-f598-4677-a031-05466d1404a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d67a74f-a3f4-4fa3-9893-c7dcf2a6dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = make_blobs(\n",
    "    n_samples=1_000,\n",
    "    n_features=2,\n",
    "    centers=7,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a26f348-afb7-42e1-9a31-b3c9cf10b797",
   "metadata": {},
   "source": [
    "## DiviK instance building\n",
    "\n",
    "`DiviK` requires `kmeans` instance, which should implement `AutoKMeans` interface.\n",
    "\n",
    "`AutoKMeans` interface gathers all methods which automatically tune the number of clusters in the `scikit-learn`-compatible K-Means algorithm implementations.\n",
    "\n",
    "`divik` library provides two implementations of `AutoKMeans` interface: `DunnSearch` and `GAPSearch`, both in the `divik.cluster` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c853d6f5-fc3b-48e7-b871-d3ada70c3667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from divik.cluster import (\n",
    "    DiviK,\n",
    "    DunnSearch,\n",
    "    GAPSearch,\n",
    "    KMeans\n",
    ")\n",
    "from sklearn.cluster import KMeans as sklKMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9282a635-ec61-411d-9e60-783e7051f305",
   "metadata": {},
   "source": [
    "### Minimal `DiviK` example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "034ac039-d536-4662-bcc9-771948227cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_divik = DiviK(\n",
    "    kmeans=DunnSearch(  # we want to use Dunn's method for finding the optimal number of clusters\n",
    "        kmeans=KMeans(\n",
    "            n_clusters=2,  # it is required, like in scikit-learn, but you can provide any number here,\n",
    "                           # DunnSearch will override it anyway\n",
    "        ),\n",
    "        max_clusters=5,  # for the sake of the example I'll keep it low\n",
    "    ),\n",
    "    minimal_size=100,  # for the sake of the example, I won't split clusters with less than 100 elements\n",
    "    filter_type='none',  # we have 2 features in sample data, feature selection would be pointless\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7c5d5f1-aef0-45b9-9c1e-dd304c8a0a99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiviK(filter_type='none',\n",
       "      kmeans=DunnSearch(kmeans=KMeans(n_clusters=2), max_clusters=5),\n",
       "      minimal_size=100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimal_divik.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd885fc7-71c8-47a6-bda1-5aa1a7cf7a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimal_divik.n_clusters_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c738fd6-70be-4987-8400-24010367906d",
   "metadata": {},
   "source": [
    "In the above case, the only stop criterion for the algorithm, is reaching the subgroup size below `minimal_size`, which is a naive approach.\n",
    "\n",
    "### `DiviK` example with data heterogeneity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6306c799-e94b-4d34-b751-6b998e804542",
   "metadata": {},
   "outputs": [],
   "source": [
    "divik = DiviK(\n",
    "    kmeans=DunnSearch(  # we want to use Dunn's method for finding the optimal number of clusters\n",
    "        kmeans=KMeans(\n",
    "            n_clusters=2,  # it is required, like in scikit-learn, but you can provide any number here,\n",
    "                           # DunnSearch will override it anyway\n",
    "        ),\n",
    "        max_clusters=5,  # for the sake of the example I'll keep it low\n",
    "    ),\n",
    "    fast_kmeans=GAPSearch(  # this one is for assessment, if we should split a subregion\n",
    "        kmeans=KMeans(\n",
    "            n_clusters=2,  # as above\n",
    "        ),\n",
    "        max_clusters=2,  # For the sake of heterogeneity check, it should be 2 for GAP index.\n",
    "                         # GAP index always looks for \"first feasible\", so if one cluster\n",
    "                         # does not yield the right solution, we split.\n",
    "    ),\n",
    "    minimal_size=100,  # for the sake of the example, I won't split clusters with less than 100 elements\n",
    "    filter_type='none',  # we have 2 features in sample data, feature selection would be pointless\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2173c997-5461-4fb0-9301-a7e96140161b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiviK(fast_kmeans=GAPSearch(kmeans=KMeans(n_clusters=2), max_clusters=2),\n",
       "      filter_type='none',\n",
       "      kmeans=DunnSearch(kmeans=KMeans(n_clusters=2), max_clusters=5),\n",
       "      minimal_size=100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divik.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cc37f10-09af-4025-9646-fc05b514a151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divik.n_clusters_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a40d0d6-3282-4631-b3b4-a7c1dac1f4e7",
   "metadata": {},
   "source": [
    "With heterogeneity check it is more likely that the discovered structure corresponds to the actual data, because we don't create so much artificial clusters.\n",
    "\n",
    "### `scikit-learn` K-Means implementation\n",
    "\n",
    "You can use `scikit-learn` implementation of K-Means algorithm if you want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8186bf43-e68e-4e64-8af4-1a6864058e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_kmeans = sklKMeans(\n",
    "    n_clusters=2,  # whatever actually, as explained above\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "skl_divik = DiviK(\n",
    "    kmeans=DunnSearch(  # we want to use Dunn's method for finding the optimal number of clusters\n",
    "        kmeans=skl_kmeans,\n",
    "        max_clusters=5,  # for the sake of the example I'll keep it low\n",
    "    ),\n",
    "    fast_kmeans=GAPSearch(  # this one is for assessment, if we should split a subregion\n",
    "        kmeans=skl_kmeans,\n",
    "        max_clusters=2,  # For the sake of heterogeneity check, it should be 2 for GAP index.\n",
    "                         # GAP index always looks for \"first feasible\", so if one cluster\n",
    "                         # does not yield the right solution, we split.\n",
    "    ),\n",
    "    minimal_size=100,  # for the sake of the example, I won't split clusters with less than 100 elements\n",
    "    filter_type='none',  # we have 2 features in sample data, feature selection would be pointless\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efdd148f-a3b6-4e4a-b82d-0cb52a58c72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DiviK(fast_kmeans=GAPSearch(kmeans=KMeans(n_clusters=2, random_state=42),\n",
       "                            max_clusters=2),\n",
       "      filter_type='none',\n",
       "      kmeans=DunnSearch(kmeans=KMeans(n_clusters=2, random_state=42),\n",
       "                        max_clusters=5),\n",
       "      minimal_size=100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl_divik.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2837c909-7af3-44b5-9c2d-f0da819e9040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl_divik.n_clusters_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
